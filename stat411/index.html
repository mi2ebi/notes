<!doctype html>
<html>
  <head>
    <title>stat 411</title>
    <link rel="stylesheet" href="https://mi2ebi.github.io/style.css" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <style>
      dt.procedure {
        color: var(--green-warmer);
      }
    </style>
  </head>
  <body>
    <h1 class="h0">stat 411</h1>
    <h1>ch1 basics</h1>
    <h2>1.1 intro/overview</h2>
    <dl>
      <dt>statistics</dt>
      <dd>methods to collect/analyse/present/interpret data <i>inductively</i></dd>
      <dd>science of data, decisionmaking, methodology</dd>
    </dl>
    <p>types of statistics:</p>
    <ol>
      <li>
        <b>descriptive</b> &ndash;
        methods to organise/display/decribe data
      </li>
      <li>
        <b>inferential</b> &ndash;
        methods to utitlse data to make decisions and models etc
      </li>
    </ol>
    <p>the generalisation from sample to population is <b>statistical inference</b></p>
    <h3>history</h3>
    <p>aristotle combined empricism and rationalism</p>
    <p>see also <i lang="la">cōgitō ergō sum</i></p>
    <p>
      after the industrial revolution there was more of an economy, and governments
      needed to find out different information about their populations
    </p>
    <blockquote>
      there are 3 lies in society: lies, damned lies, and statistics<br />
      <cite>&ndash; popularised by mark twain</cite>
    </blockquote>
    <p>book rec: <i>how to lie with statistics</i></p>
    <h2>1.3 experiments and data</h2>
    <p>no two measurements are ever exactly the same</p>
    <h2>1.4 inferences</h2>
    <dl>
      <dt>population</dt>
      <dd>
        all elements under study being characterized by some <b>parameter</b>:
        eg population mean, \(\mu\)
      </dd>
      <dt>sample</dt>
      <dd>
        a properly chosen subset of a population characterized by a <b>statistic</b>:
        eg sample mean, \(\bar x\)
      </dd>
      <dt>sample space</dt>
      <dd>collection of all possible outcomes of an experiment</dd>
      <dt>random sample</dt>
      <dd>
        a sample where every element of the population has the same likelihood to be
        chosen (assuming the population is finite)
      </dd>
      <dt class="procedure">simple random sample</dt>
      <dd class="dedent"><ol>
        <li>define the population</li>
        <li>pick a sample size \(n\)</li>
        <li>randomly select a sample eg using an rng</li>
      </ol></dd>
    </dl>
    <p><img src="sampling.png" /></p>
    <h2>1.5 data</h2>
    <dl>
      <dt>element/object/subject</dt>
      <dd>an imate we collect data about</dd>
      <dt>variable</dt>
      <dd>a characteristic being studied</dd>
      <dt>observation/measurement</dt>
      <dd>numerical values of a variable for an element</dd>
    </dl>
    <h3>places to get data from</h3>
    <p>census, survey, experiment, simulation, ...</p>
    <p>but to get scientific data we need 2 <b>statistical studies</b></p>
    <dl>
      <dt>observational study</dt>
      <dd>conducted in a way where we have no control over any variables</dd>
      <dd>
        <b>cross-sectional</b> &ndash;
        collect data at one point in time
      </dd>
      <dd>
        <b>longitudinal/cohort</b> &ndash;
        collect data over a period of time about common factors
      </dd>
      <dt>experimental study</dt>
      <dd>
        we have control over 1 variable. <b>treatment</b> group and <b>control</b>
        group. eg clinical trials
      </dd>
      <dd>
        principles (cf ch13-15 which we're not covering):<br />
        <b>replication</b>, <b>randomization</b>, <b>blocking/blinding</b>
      </dd>
    </dl>
    <h2>1.6 types of variables</h2>
    <dl>
      <dt>quantitative variables</dt>
      <dd><b>discrete</b> &ndash; countable</dd>
      <dd><b>continuous</b> &ndash; any numerical value</dd>
      <dt>qualitative/categorical variables</dt>
      <dd><b>nominal</b> &ndash; not rankable</dd>
      <dd><b>ordinal</b> &ndash; rankable</dd>
    </dl>
    <p>levels of measurement</p>
    <ul>
      <li>nominal</li>
      <li>ordinal</li>
      <li>
        <b>interval</b> &ndash;
        no such thing as absolute zero. eg we can't say las vegas is twice as hot as
        chicago if it's 60&deg; in vegas and 30&deg; in chicago
      </li>
      <li><b>ratio</b> &ndash; there is a possible absolute zero</li>
    </ul>
    <h2>1.3 measures of central tendency</h2>
    <p>if we have a random sample \(x_1, x_2, \dots, x_n\) of size \(n\)</p>
    <dl>
      <dt>measure of central tendency</dt>
      <dd>some indication of where the center of the dataset is</dd>
      <dt>mean</dt>
      <dd>simplest and nicest. "center of gravity"</dd>
      <dd>\(
        \=x = \frac1n \sum\limits_{i = 1}^n x_i = \sum\limits_{i = 1}^n \frac{x_i}n
      \)</dd>
      <dt>trimmed mean</dt>
      <dd>
        mean with some of the potential outliers cut out, eg 5% trimmed mean means
        taking only the middle 90% of the data
      </dd>
      <dt>median</dt>
      <dd>middle value in the ordered dataset</dd>
      <dd>if \(n\) is odd, \(\~x = x_{\frac{n + 1}2}\)</dd>
      <dd>
        if \(n\) is even, \(\~x = \frac12\left(x_{\frac n2} + x_{\frac n2 + 1}\right)\)
      </dd>
      <dd>median is less sensitive to outliers so it is more <b>robust</b></dd>
      <dt>mode</dt>
      <dd>values that occur most frequently</dd>
      <dd>one mode &rarr; <b>unimodal</b>, two modes &rarr; <b>bimodal</b>, etc</dd>
    </dl>
    <p>if the histogram of the data is symmetric, \(\text{mode} = \~x = \=x\)</p>
    <p>if the histogram is skewed to (has a longer tail on) the right, \(
      \text{mode} &lt; \~x &lt; \=x
    \)</p>
    <h2>1.4 measures of variability</h2>
    <dl>
      <dt>range</dt>
      <dd>difference in the max and min of the dataset</dd>
      <dt>(individual) deviation</dt>
      <dd>\(x_i - \=x\)</dd>
      <dt>sample variance</dt>
      <dd>\(
        s^2
        = \frac1{n - 1} \sum\limits_{i = 1}^n (x_i - \=x)^2
        = \frac1{n - 1} \left(
          \sum\limits_{i = 1}^n x_i^2 - \frac{\left(\sum x_i\right)^2}n
        \right)
      \)</dd>
      <dt>standard deviation</dt>
      <dd>\(s = \sqrt{s^2}\)</dd>
    </dl>
    <p>the second form is nicer for computation since you don't need eg 2 loops</p>
<pre>
<span class="keyword">let mut</span> <span class="variable">sum_squares</span> @ <span class="keyword">mut</span> <span class="variable">sum</span> = <span class="constant">0</span>;
<span class="keyword">let</span> <span class="variable">n</span> = <span class="variable">sample</span>.<span class="function">len</span>() <span class="keyword">as</span> <span class="type">f64</span>;
<span class="keyword">for</span> <span class="variable">x</span> <span class="keyword">in</span> <span class="variable">sample</span> {
  <span class="variable">sum</span> += <span class="variable">x</span>;
  <span class="variable">sum_squares</span> += <span class="variable">x</span> * <span class="variable">x</span>;
}
<span class="keyword">let</span> <span class="variable">s2</span> = <span class="constant">1.</span>/(<span class="variable">n</span>-<span class="constant">1.</span>) * (<span class="variable">sum_squares</span> - <span class="variable">sum</span>*<span class="variable">sum</span>/<span class="variable">n</span>);
<span class="keyword">let</span> <span class="variable">s</span> = <span class="variable">s2</span>.<span class="function">sqrt</span>();
</pre>
    <p>the sum of deviations is \(\sum\limits_{i = 1}^n (x_i - \=x) = 0\)</p>
    <dl>
      <dt>coefficient of variation</dt>
      <dd>for samples: \(\text{CV} = 100\% \cdot s/\=x\)</dd>
      <dd>for populations: \(\text{CV} = 100\% \cdot \sigma/\mu\)</dd>
      <dt>quartiles</dt>
      <dd>divide the sample into 4 equal parts (by #observations)</dd>
      <dd>\(Q_1\), med, \(Q_3\)</dd>
      <dt>interquartile range</dt>
      <dd>\(\text{IQR} = Q_3 - Q_1\)</dd>
      <dd>middle 50% of the sample</dd>
      <dt>five-number summary</dt>
      <dd>the three quartiles along with min and max</dd>
      <dd>used to make a <b>boxplot</b></dd>
      <dt>inner fence</dt>
      <dd>the range between \(Q_1 - 1.5~\text{IQR}\) and \(Q_3 + 1.5~\text{IQR}\)</dd>
      <dd>outside this are <b>mild outliers</b></dd>
      <dt>percentiles</dt>
      <dd>like quartiles but with 100 equal parts</dd>
      <dd>\(Q_1 = p_{25}\) etc</dd>
      <dd>
        \(p_k = \frac{nk}{100}\)th observation and says that \(k\)% of the observations
        are at or below that value
      </dd>
      <dt>percentile rank</dt>
      <dd>figure out what percentile an observation is</dd>
      <dd>\(100 \cdot (\text{\# observations} &lt; x_i) / n\)</dd>
    </dl>
    <h2>1.10 empirical rule & z-score</h2>
    <dl>
      <dt>empirical rule</dt>
      <dd>
        for a normal (bell shaped) distribution, <ul>
          <li>\(\=x \pm s\) contains 68% of values</li>
          <li>\(\=x \pm 2s\) &rarr; 95%</li>
          <li>\(\=x \pm 3s\) &rarr; 99.7%</li>
        </ul>
        so almost the entire dataset fits in 6 standard deviations.
        this is only a rule of thumb. also called the <b>6&sigma; rule</b>
      </dd>
      <dt>z-score</dt>
      <dd>\(z_i = \frac{x_i - \=x}s\)</dd>
      <dd>unit-free!</dd>
      <dd>if \(|z| &gt; 2\) for an observation it could be considered an outlier</dd>
      <dd>converting \(x_i\) to \(z_i\) is called <b>standardization</b></dd>
      <dd>and \(x_i = \=x + z_is\) for <b>destandardization</b></dd>
    </dl>
    <h1>ch2 probability</h1>
    <h2>2.1 intro</h2>
    <dl>
      <dt>statistical experiment</dt>
      <dd>process of generating outcomes that cannot be predicted in advance</dd>
      <dt>sample space</dt>
      <dd>set of all possible outcomes. denoted \(S\) or \(\Omega\)</dd>
      <dt>event</dt>
      <dd>any subset of \(S\), denoted with a capital letter</dd>
    </dl>
    <p>eg rolling a die: \(S = \set{1, 2, 3, 4, 5, 6}\)</p>
    <dl>
      <dt>probability</dt>
      <dd>numerical measure of how likely some event is, denoted \(P(\cdot)\)</dd>
    </dl>
    <p>kolmogorov's axioms of probability:</p>
    <ol>
      <li>\(0 \le P(A) \le 1\) for any event \(A\)</li>
      <li>\(P(S) = 1\)</li>
    </ol>
    <p>
      assuming all outcomes in \(S\) are equally likely,
      \(P(A) = \frac{\#A}{\#S}\)
    </p>
    <dl>
      <dt>venn diagram</dt>
      <dd>depiction of the relationship btwn sample space and events</dd>
      <dt>tree diagram</dt>
      <dd>(pp37-38)</dd>
    </dl>
    <h2>2.2 set operations</h2>
    <dl>
      <dt>empty set</dt>
      <dd>\(\emptyset\), the set with nothing in it. \(P(\emptyset) = 0\)</dd>
      <dt>intersection</dt>
      <dd>\(A \cap B = \set{x : x \in A \land x \in B}\)</dd>
      <dt><i>mutually exclusivei / disjoint</i></dt>
      <dd>if \(A \cap B = \emptyset\)</dd>
      <dt>union</dt>
      <dd>\(A \cup B = \set{x : x \in A \lor x \in B}\)</dd>
      <dt>complement</dt>
      <dd>\(A^\complement = A' = \=A = \set{x : x \not\in A}\)</dd>
    </dl>
    <p><img src="setoperations.png" /></p>
    <dl>
      <dt>rule of addition</dt>
      <dd>\(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)</dd>
      <dt>rule of complement</dt>
      <dd>\(P(A^\complement) = 1 - P(A)\)</dd>
      <dt>demorgan's laws</dt>
      <dd>\((A \cup B)^\complement = A^\complement \cap B^\complement\)</dd>
      <dd>\((A \cap B)^\complement = A^\complement \cup B^\complement\)</dd>
      <dt>distributive laws</dt>
      <dd>\(A \cap (B \cup C) = (A \cap B) \cup (A \cap C)\)</dd>
      <dd>\(A \cup (B \cap C) = (A \cup B) \cap (A \cup C)\)</dd>
      <dt>odds <i>in favor of A</i></dt>
      <dd>\(\frac{P(A)}{P(A^\complement)}\)</dd>
      <dd>result between 0 and \(\infty\) exclusive</dd>
    </dl>
    <h2>2.4 counting sample points</h2>
    <dl>
      <dt>combinatorics</dt>
      <dd>study of enumeration</dd>
      <dt>multiplication principle</dt>
      <dd>
        for \(k\) choices, if there are \(n_i\) ways to make choice \(i\), then the
        total number of possibilities is \(\prod\limits_{i = 1}^k n_i\)
      </dd>
      <dt>permutation</dt>
      <dd>an ordered subset</dd>
      <dt>factorial</dt>
      <dd>for any integer \(n \ge 0\), \(n! = \prod\limits_{i = 1}^n i\)</dd>
      <dd>specialcase \(0! = 1\)</dd>
    </dl>
    <p>the number of permutations of \(r\) objects among a set of \(n\) is \(P_{n, r} = \frac{n!}{(n - r)!}\)</p>
    <dl>
      <dt>combination</dt>
      <dd>an unordered subset</dd>
    </dl>
    <p>
      the number of ways to choose \(r\) of \(n\) objects, regardless of order, is \[
        C_{n, r} = {n \choose r} = \frac{P_{n, r}}{r!} = \frac{n!}{r! (n - r)!}
      \]
    </p>
    <p>
      \(n \choose r\) is also called the <b>binomial coefficient</b> and is equal to
      \({n \choose n - r}\)
    </p>
    <p><img src="urn.png" /></p>
    <dl>
      <dt>multinomial combination</dt>
      <dd>
        if there are \(k\) kinds, then the ways to choose partition the set into kinds
        is \[{n \choose n_1, n_2, \dots, n_k} = \frac{n!}{\prod_{i = 1}^k n_i!}\]
      </dd>
    </dl>
    <p>
      eg there are \({n \choose 4, 4, 2, 1} = 34650\) ways to rearrange the letters in
      "mississippi"
    </p>
    <script src="../temml.min.js"></script>
    <script>temml.renderMathInElement(document.body, {trust: true});</script>
  </body>
</html>
